# Supervizované v. nesupervizované učení
## Supervizované
- Modelu poskytujeme známé hodnoty.
## Nesupervizované
- Hledáme skrytou strukturu dat.
- Typickým příkladem je **shlukování**.

# Klasifikace / Regrese
- Suprevizované učení
- Snažíme se zjistit, jak vysvětlovanou proměnnou $Y$ ovlivňují příznaky $X_1, X_2, \ldots, X_p$, hledáme funkční vztah, aby "co nejvíce platilo" $Y \approx f(X_1, X_2, \ldots, X_p)$.
- Pokud $f$ může nabývat jen několika málo hodnot, mluvíme o **klasifikaci**.
- Pokud může nabývat tolika hodnot, že ji lze považovat za spojitou, mluvíme o **regresi*.
- **Rozhodovací stromy** lze použít pro oba typy problému.

## Konstrukce stromu
- Zkoušet všechny možné stromy je disproporčně náročné.
- Používáme **hladový algoritmus** označovaný jako **ID3**.
	- Vybereme příznak který dělí data na dvě co nejvíce uspořádané části.
	- Míru uspořádání měříme pomocí entropie - entropie pro množinu vstupních dat $\mathcal{D}$
	- Pokud by se jednalo o binární příznak tak $H(\mathcal{D}) = -p_0 \log{p_0} -p_1 \log{p_1}$, kde $p_0$ a $p_1$ vyjadřují počty nul a jedniček.
	- Vzorec pro nebinární příznak s $k$ různými hodnotami $$H(\mathcal{D}) = \sum^{k-1}_{i = 0} - p_i\log_2 p_i$$
##  Míra klasifikační přesností modelu
-  $$\frac{\text{počet správně klasifikovaných dat}}{\text{počet všech dat}}$$
- Nechceme aby byl strom co nejlepší na trénovacích datech, ale na všech datech.
- Rozdělíme si data na data pro učení a pro data pro měření přesnosti - na těch změříme přesnost modelu, abychom se nemuseli vázat na přesnost u trénovacích dat.
- **overfitting** - když až moc přizpůsobíme modle trénovacím datům, takže přestane být přesný pro reálná data.
- 